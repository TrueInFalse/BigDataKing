# 大数据相关面试题汇总

## 大数据相关面试题每日五问（一）25.4.7

### 1.1 SQL的偏移量怎么实现，怎么排序？

在 SQL 中，排序通常通过 ORDER BY 实现，可以指定某一列按升序（ASC）或降序（DESC）排列，而偏移量（即从第几条记录开始返回）则通过 LIMIT 和 OFFSET 实现，常用于分页查询。例如，ORDER BY score DESC 表示按照成绩从高到低排序，LIMIT 10 OFFSET 10 表示跳过前 10 条记录，返回接下来的 10 条数据，从而实现第 11 到第 20 条记录的查询。需要注意的是，偏移量查询必须配合排序使用，否则结果顺序不确定。在 MySQL 中也可以使用简写形式 LIMIT 10, 10，意思是从第 11 条开始取 10 条。而在 Hive 中，由于 ORDER BY 会将所有数据集中到一个 reducer 上，效率较低，因此更常使用 DISTRIBUTE BY 配合 SORT BY 来实现更高效的排序和分页。

### 1.2 MapReduce中的数据倾斜你了解多少？如何解决数据倾斜？

在 MapReduce 中，数据倾斜是指某些 key 的数据量远大于其他 key，导致某些 reducer 处理时间远长于其他 reducer，从而拉低整体作业效率。数据倾斜常发生在 shuffle 阶段，原因包括 key 分布不均、热点 key 过多或 join 操作中某一表数据倾斜。为了解决数据倾斜，可以采用多种方法：一是使用 随机前缀法 将热点 key 拆分为多个子 key，分散到不同 reducer，再在 reduce 端汇总；二是对大表和小表 join 时使用 map 端 join 或 广播小表，避免 reducer 端数据倾斜；三是通过 采样分析 key 分布，定位热点数据并做针对性优化；四是对于极端倾斜的 key，也可以考虑 单独处理 或 排除后单独合并。总之，关键在于打散热点 key，均衡 reducer 的数据负载。

### 1.3 Spark如何划分stage？

在 Spark 中，stage 的划分是基于 RDD 之间的依赖关系 来进行的，具体来说，只有遇到 宽依赖（wide dependency） 时才会划分新的 stage。窄依赖（如 map、filter）是上一个 RDD 的每个分区只依赖上一个 RDD 的一个分区，因此可以在一个 stage 内顺序执行；而宽依赖（如 groupByKey、reduceByKey）会导致某个分区依赖上一个 RDD 的多个分区，涉及到 shuffle 操作，所以需要划分新的 stage。Spark 会从最终的 action 操作开始，反向追踪 RDD 的依赖关系，当遇到宽依赖时就断开，形成一个新的 stage，直到最前面的数据源。划分完成后，Spark 会将每个 stage 中的任务分发给不同 executor 的 task 去执行。这样划分的目的是为了优化执行计划，提高并行度和执行效率。

### 1.4 数仓理论了解多少？简单说一下分层。

数仓理论主要是为了解决数据整合、清洗和高效分析的问题，它强调数据的统一口径、稳定性和可复用性。在数仓架构中，通常采用分层设计，常见的分层包括：ODS（操作数据层），用于存储最原始的、从业务系统同步过来的数据，基本不做处理；DWD（数据明细层），对 ODS 的数据进行清洗、去重、标准化，保留最详细的事实数据，是数据加工的基础层；DWS（数据汇总层），对 DWD 层的数据按主题和维度进行聚合、统计，适用于业务分析需求；ADS（应用数据层），面向具体的报表和场景需求进行加工，提供最终的分析结果或接口支持。通过分层设计可以提高数据质量、增强可维护性，并降低上下游系统之间的耦合。

### 1.5 给你一个数据需求，开发思路是怎么样的，简单描述一下。

面对一个数据需求，通常的开发思路可以分为五个步骤：第一，明确业务需求，与需求方沟通清楚要解决的问题、核心指标和口径，确保对业务目标理解一致；第二，梳理数据来源，确定需要哪些原始表、字段、分区以及数据更新周期；第三，设计数仓模型，根据维度与事实的关系，确定建表逻辑，分清明细层（DWD）、汇总层（DWS）或应用层（ADS）的位置；第四，编写 ETL 脚本，使用 Hive、Spark 等工具编写 SQL 或代码实现数据的清洗、转换和加工，同时做好数据质量校验和分区管理；最后，输出数据结果，将结果表或接口对接给下游使用方，如报表系统、大屏展示或接口服务，并做好上线后的监控和维护。整个过程中要注重沟通、版本控制和数据口径的一致性，确保数据的准确性和稳定性。


## 大数据相关面试题每日五问（二）25.4.8

### 2.1 常见的窗口排序函数你知道哪些？说一下他们各自作用。

常见的窗口排序函数主要包括 ROW_NUMBER()、RANK()、DENSE_RANK()、NTILE() 等，它们常配合窗口函数 OVER(PARTITION BY ... ORDER BY ...) 使用，作用是对分组内的数据进行排序和排名。ROW_NUMBER() 是最常用的，给每一行按顺序分配唯一的序号，不会出现重复；RANK() 会对相同值的记录赋相同名次，跳过后续名次（比如并列第 2，下一名是第 4）；DENSE_RANK() 同样对相同值的记录赋相同名次，但不会跳过名次（并列第 2，下一名是第 3）；NTILE(n) 是把分组内的记录按顺序平均分成 n 份，为每行分配一个从 1 到 n 的桶编号。它们常用于如 TopN 查询、分组内排序、分位分析等场景，能在保留全部数据的同时进行灵活排名。


### 2.2 HDFS如何保证数据的可靠性和高可用性？它的副本机制是如何工作的？

HDFS 通过副本机制来保证数据的可靠性和高可用性，每个文件被切分成多个块（Block），每个块默认会在集群中存储 3 个副本，分别保存在不同的 DataNode 上，从而避免因单点故障导致数据丢失。当某个副本所在的节点宕机或数据损坏时，NameNode 会感知并在其他健康节点上重新复制该副本，自动修复数据，确保副本数维持在配置值以上；同时，HDFS 的 NameNode 虽然是管理元数据的核心，但通过配置 主备 NameNode（HA 高可用架构），结合 Zookeeper 实现故障自动切换，避免了单点故障风险。整体上，HDFS 通过副本冗余、故障感知、自愈机制和主备架构，保障了系统的稳定性与数据安全。


### 2.3 ES是如何保证数据高可用性的？如果一个节点宕机，系统会如何处理？

Elasticsearch 通过主分片和副本分片机制来实现数据的高可用性。每个索引的数据会被划分为多个主分片（primary shard），并为每个主分片配置一个或多个副本分片（replica shard），这些分片分布在不同的节点上。当一个节点宕机时，集群中的 Master 节点会立即检测到，并将其上的主分片的副本分片提升为新的主分片，继续对外提供读写服务，同时将缺失的副本在其他节点上重新分配和恢复，确保数据不丢失、服务不中断。此外，Elasticsearch 的分布式架构可以自动进行分片重分配、数据均衡和故障转移，从而实现系统的自我修复和持续可用。


### 2.4 Hive表里的分桶有哪几种形式，分桶与分区的区别？什么时候要去做分桶？

Hive 中的分桶是通过对某一列进行哈希计算，再将数据平均分配到固定数量的桶中，常见形式是在建表时使用 CLUSTERED BY (列名) INTO N BUCKETS 来定义分桶。分桶和分区的主要区别在于：分区是将数据按目录层级物理划分，适用于大范围数据的筛选，提升查询效率；而分桶是在分区或全表内部的进一步划分，提高了数据的分布均匀性和采样、Join 的效率。通常在以下场景下需要使用分桶：一是当需要对大表做 桶映射 Join（bucket map join），提升 Join 性能；二是在使用 抽样查询（tablesample） 时保证样本均匀性；三是为了优化数据倾斜问题或提升并行度。简而言之，分区适用于大粒度的数据划分，分桶适用于细粒度的数据优化。


### 2.5 Spark调优思路?

Spark 调优的整体思路可以从 资源配置、并行度控制、Shuffle 优化、缓存策略和代码逻辑 五个方面入手。首先是资源配置，要合理设置 executor 的数量、内存（executor-memory）和 CPU 核数（executor-cores），避免资源浪费或不足；其次是并行度控制，通过设置 spark.sql.shuffle.partitions 或 RDD 的 repartition 来调整任务并行度，防止过多或过少的分区导致性能问题；在 Shuffle 优化 方面，要尽量减少 shuffle 操作，比如用 map-side join 或 broadcast join 替代大表 shuffle；对于 缓存策略，使用 persist 或 cache 缓存重用的中间结果，减少重复计算；最后，优化 代码逻辑，如避免冗余转换、过滤尽量提前、少用宽依赖操作等，提升 DAG 执行效率。调优过程中还要结合 Spark UI 分析瓶颈，定位 Stage 执行慢的具体原因，做到有的放矢。

## 大数据相关面试题每日五问（三）25.4.9

### 3.1 对ES的倒排索引了解多少？工作原理？如何提高其查询效率？

Elasticsearch 使用的是倒排索引（Inverted Index），这是实现全文检索的核心机制。其原理是：将每个文档中的字段内容进行分词处理，然后为每个词项建立一个词典（term），记录该词在哪些文档（文档 ID）中出现，以及出现的位置和频率。这样查询时不是遍历每个文档去找关键词，而是直接查词典获取相关文档列表，极大提升了检索效率。为了进一步提高查询性能，可以采取多种优化手段：一是合理设置字段类型和分词器，减少无效字段的索引；二是使用 keyword 类型字段做精确匹配，避免不必要的全文分词；三是通过设置合适的 filter 缓存结果、避免重复计算；四是开启 doc_values 支持聚合、排序等操作，减少内存消耗；五是避免过度嵌套结构，必要时使用 flattened 或 join 优化文档结构。此外，合理的索引设计、分片分配和冷热数据分离也是保障查询效率的重要手段。

### 3.2 了解MySQL中的事务吗？它的ACID特性指的是什么？

MySQL 中的事务是指一组操作的集合，要么全部执行成功，要么全部回滚撤销，常用于保证数据的一致性与完整性。事务具有四大特性，也就是 ACID：原子性（Atomicity） 指事务中的操作要么全部完成，要么全部不做，出现错误可以回滚；一致性（Consistency） 保证事务执行前后数据都满足数据库的约束规则，不会出现破坏数据逻辑的状态；隔离性（Isolation） 表示多个事务并发执行时互不干扰，常见的隔离级别包括读未提交、读已提交、可重复读、串行化；持久性（Durability） 指事务一旦提交，对数据的修改就是永久性的，即使系统宕机也不会丢失。MySQL 中默认使用 InnoDB 引擎来支持事务，其通过 redo log、undo log 和锁机制来实现对 ACID 的保障。

### 3.3 简述数据仓库中“维度”和“事实”表的区别及其作用

在数据仓库中，维度表和事实表是构建星型或雪花模型的核心组成部分。事实表（Fact Table） 用于存储与业务事件相关的度量值或指标数据，例如订单金额、销售数量等，通常数据量大，记录的是“发生了什么”；而 维度表（Dimension Table） 则存储描述事实的维度信息，比如时间、地区、产品、用户等，是对事实的多角度分析视角。二者的主要区别在于：事实表关注“数值和业务行为”，维度表关注“描述和分类信息”；事实表一般包含外键关联多个维度表，而维度表一般数据量小但字段丰富，便于查询和筛选。在实际应用中，通过维度表可以对事实表的数据进行分组、聚合、切片和钻取，是实现多维分析（OLAP）的基础。

### 3.4 构建数仓的模型有哪些？展开讲讲。

构建数仓的常见模型主要包括星型模型、雪花模型和事实星座模型。星型模型是最常用的一种，其特点是一个中心事实表直接连接多个维度表，结构简单、查询高效，适合于查询频繁、维度较少的场景；雪花模型是在星型模型基础上对维度表进一步规范化，将维度表拆分为多个层级子表，形成树状结构，减少冗余、节省存储，但查询时关联复杂、效率较低；事实星座模型（也叫复合星型模型）是多个事实表共享维度表的结构，适用于存在多个业务过程（如订单、支付、退货等）且共享维度的复杂分析需求。选择哪种模型需根据业务需求、数据复杂度和查询性能权衡，实际开发中也常采用分层建模（ODS、DWD、DWS、ADS）与上述模型相结合，实现数据的稳定、复用与灵活分析。

### 3.5 HDFS 的写数据流程是怎样的？如果一个 DN在写入过程中发生故障，Hadoop 会如何处理？

HDFS 中的写数据流程从客户端开始，首先客户端向 NameNode 请求文件写入权限。NameNode 确认文件不存在后，将文件写入的权限以及负责存储数据块的 DataNode 信息返回给客户端。客户端然后会与 DataNode 建立连接，并通过一个个数据块的方式进行写入。每个数据块（Block）会按照一定的副本策略（默认三个副本）分配到多个 DataNode 上。客户端向每个 DataNode 传输数据时，会将数据写入第一个数据块，完成后接着写第二个、第三个，以此类推。如果在写入过程中，某个 DataNode 发生故障，NameNode 会根据副本机制将数据复制到其他健康的 DataNode 上，确保数据不会丢失。通过心跳机制和副本机制，DataNode 故障会被检测到，并且数据会自动恢复到最新副本。故障发生时，HDFS 会根据剩余副本的数据恢复丢失的部分。


>1、Client通过Distributed FileSystem模块向NN请求上传文件，NN检查目标文件是否已存在，父目录是否存在
>
>2、NN返回是否可以上传
>
>3、Client请求第一个block上传哪几个DN服务器上
>
>4、NN返回3个DN节点，分别为DN1、DN2、DN3
>
>5、Client通过FSDataOutputStream模块请求DN1建立传输通道，DN1收到请求会继续调用DN2,DN2继续调用DN3
>
>6、DN3应答DN2，DN2应答DN1，DN1应答Client
>
>7、Client开始往DN1上传第一个block(先读取数据放到一个本地磁盘缓存)，以packet为单位，DN1收到一个packet就会上传给DN2,DN2传给DN3；DN1每传一个packet会放入到一个应答队列等待应答
>
>8、当一个block传输完成后，Client会再次请求NN上传第二个block的服务器，重复执行3-7


## 大数据相关面试题每日五问（四）25.4.10

### 4.1 对MySQL中的锁机制了解多少？展开说说。

MySQL 中的锁机制是保证并发事务数据一致性的重要手段，主要分为表级锁、行级锁和意向锁三类。其中，表级锁作用于整张表，粒度大、开销小，适用于读多写少的场景，如 MyISAM 引擎；行级锁作用于具体数据行，粒度小、并发高，是 InnoDB 的核心优势，适用于高并发写入场景。InnoDB 还引入了 意向锁（Intention Lock），用于协调多事务间的锁兼容性，避免全表扫描判断冲突。行锁又细分为 共享锁（S锁） 和 排它锁（X锁），前者允许多个事务读取同一行，后者则独占修改。InnoDB 默认使用 两阶段锁协议，事务在需要时加锁，直到提交或回滚才释放。此外，为了防止死锁，InnoDB 会自动检测死锁并中断回滚其中一个事务。通过灵活的锁机制设计，MySQL 在保证数据一致性的同时，也兼顾了系统性能和并发效率。

### 4.2 要在MySQL数据库中优化一个慢查询，你会从哪些方面入手？

在优化 MySQL 中的慢查询时，我会从 SQL语句本身、索引设计、执行计划、数据库结构与配置 四个方面入手。首先检查 SQL 是否存在不必要的子查询、函数操作或全表扫描，尝试通过 where 条件优化、减少数据量、避免 select * 等方式提高效率；其次分析表的 索引是否合理建立，重点关注 where、join、group by 中的字段是否使用了合适的联合索引或覆盖索引；然后通过执行 EXPLAIN 分析 SQL 的执行计划，观察是否走索引、是否存在全表扫描、临时表或文件排序等性能瓶颈；再者可以考虑优化 表结构（如字段类型、分区等）或调整 数据库参数（如查询缓存、连接数、InnoDB buffer pool 大小等）；最后建议开启 慢查询日志，配合工具如 pt-query-digest 定位频繁慢查询，持续监控和调优，从而系统性地提升查询性能。

### 4.3 了解“数据血缘” 吗？它对数据管理有什么帮助？

数据血缘（Data Lineage）是指数据从源头采集、经过清洗、加工、传输、存储、再到最终使用的全流程流转关系，可以追踪“数据从哪来、到哪去、怎么变”。    它在数据管理中具有重要作用：一是便于 数据追溯与问题定位，当发现数据异常时，可以快速找到上游数据源和处理环节；二是方便 数据影响分析，比如修改某张表或字段时，可根据血缘关系判断会影响哪些下游表、报表或系统，降低风险；三是提升 数据治理与合规性，实现数据全生命周期可视、可控、可审计；四是支持 运维与优化，帮助识别冗余链路和资源浪费，提高整体系统稳定性。通过构建数据血缘图，企业能更科学高效地管理和利用数据资产，是现代数据仓库和数据中台建设的重要基础。

### 4.4 数据仓库中的OLAP和OLTP有什么区别？详细说说。

在数据仓库中，OLAP（联机分析处理）和 OLTP（联机事务处理）是两种截然不同的数据处理模式。OLTP 主要面向日常业务操作，如订单处理、用户注册等，特点是读写频繁、操作简单、并发量大、数据实时性强，数据结构高度规范化，通常运行在传统的关系型数据库上；而 OLAP 面向的是管理层或分析师的决策支持，特点是查询复杂、以读为主、数据量大、分析维度多、响应速度要求高，通常运行在数据仓库或分析型数据库中，采用星型、雪花模型等方式对数据建模。简单来说，OLTP 处理“业务操作”，强调“事务一致性和效率”；OLAP 处理“数据分析”，强调“多维聚合和查询性能”，两者服务于不同的业务目标和系统架构，常通过数据同步、ETL 等手段实现数据从 OLTP 到 OLAP 的流转。

### 4.5 谈谈你对Spark中Shuffle机制的理解。

在 Spark 中，Shuffle 是指数据在不同任务之间因依赖关系而产生的数据重分布过程，通常发生在需要跨分区聚合、排序或 join 操作时（如 groupByKey、reduceByKey、join 等）。Shuffle 会将上游任务输出的数据按照 key 分区打散，通过网络传输到下游不同的节点执行任务，这一过程会涉及磁盘读写和网络 IO，因此是 Spark 中最消耗性能的操作之一。Shuffle 会生成大量临时文件，并且在 Executor 之间建立数据拉取关系，存在资源开销和失败重试问题。为了优化 Shuffle，Spark 引入了多种机制，如使用 map-side combine 进行预聚合、合理设置 partition 数量、避免使用 groupByKey 等高开销算子，并通过 Tungsten 项目提升序列化与内存管理性能。理解 Shuffle 的原理和触发场景，有助于我们在编写 Spark 程序时减少 Shuffle 次数、优化 DAG 结构，从而提升整体计算效率。


## 大数据相关面试题每日五问（五）25.4.11

### 5.1数据仓库的基本概念是什么？它与传统的数据库系统有何不同？

数据仓库是面向主题的、集成的、相对稳定的、反映历史变化的数据集合，主要用于支持企业管理决策。它与传统数据库系统最大的不同在于：传统数据库（OLTP） 主要用于处理日常业务操作，如插入、修改、删除，关注的是单点数据的事务一致性与实时性；而 数据仓库（OLAP） 更关注对大规模历史数据的整合分析，支持多维度的查询、聚合、趋势分析等。数据仓库一般会经过 ETL 过程将来自多个系统的原始数据清洗、转换并统一存储，具有更强的数据集成性和可分析性；同时，它更注重查询性能优化，常用星型、雪花模型建模，牺牲部分写入效率以换取更高的读性能。简而言之，数据仓库是企业“做分析”的大脑，传统数据库则是“做业务”的心脏。


### 5.2 说一下ES中的核心组件以及各自关系作用。

Elasticsearch（ES）由多个核心组件构成，包括 索引（Index）、文档（Document）、分片（Shard）、节点（Node） 和 集群（Cluster）。索引是逻辑上的数据集合，相当于数据库；文档是索引中的最小数据单元，相当于数据库中的一行；每个索引会被划分成多个主分片和副本分片，分片是实际存储和查询的基本单位；节点是 ES 的运行实例，负责管理分片和执行请求；多个节点组成一个集群，共同管理和协调数据存储与查询任务。在整个架构中，文档被存入索引，索引被切分为分片，分片分布在节点上，节点组成集群提供服务。这些组件协同工作，支持 ES 的高可用性、分布式存储与实时搜索能力，使其在海量数据处理和全文检索场景中表现出色。

### 5.3 MySQL中如何使用子查询？子查询和连接查询（JOIN）有什么区别？

在 MySQL 中，子查询是嵌套在另一个查询语句中的 SELECT 语句，通常用于 where、from 或 select 子句中，实现按条件筛选、计算或动态生成临时表的功能，比如 SELECT * FROM orders WHERE user_id IN (SELECT id FROM users WHERE age > 30)。子查询有标量子查询、行子查询、列子查询和表子查询几种形式。而 连接查询（JOIN） 是通过共享字段将多张表横向拼接，形成一张大的结果集，常用于跨表数据整合，如 INNER JOIN、LEFT JOIN 等。两者的主要区别在于：子查询是“先算后用”，适合层次关系和逻辑嵌套，代码结构清晰但可能效率较低；JOIN 是“边算边用”，更适合大数据量下的高效关联，执行性能通常优于子查询。实际使用中需根据业务场景和性能需求选择合适方式。


### 5.4 谈谈MapReduce中的Task。

在 MapReduce 中，Task 是作业执行的最小计算单元，分为 Map Task 和 Reduce Task 两类。Map Task 负责对输入数据进行切片（Split）后并行处理，将原始数据映射成键值对（key-value）；Reduce Task 则在 Map 输出的 key 经过 Shuffle 和 Sort 过程后，对相同 key 的 value 进行归约操作，生成最终输出结果。每个 Task 都在集群中的某个节点上运行，Map Task 和 Reduce Task 是相互独立的，数量可根据数据量与集群规模动态配置。Map 任务完成后，Reduce 才开始，任务调度由 YARN 或 JobTracker 统一管理。合理设置 Task 数量、优化数据分区策略，有助于提升 MapReduce 的并行效率与容错能力，是大数据处理框架高性能的基础。


### 5.5 若MR中某个Task失败了，Hadoop会如何处理？

在 MapReduce 中，如果某个 Task（无论是 Map 还是 Reduce）失败了，Hadoop 会通过 任务重试机制 来自动处理。具体来说，任务失败后，JobTracker（或 YARN 的 ApplicationMaster）会在其他可用节点上重新调度该 Task 的副本重跑，默认最多重试 4 次（可通过参数 mapreduce.map.maxattempts 和 mapreduce.reduce.maxattempts 配置）。如果在限定次数内任务成功，则整个作业继续执行；若多次重试仍失败，整个 Job 会被标记为失败。此外，为了提高稳定性，Hadoop 会记录失败节点，并在短时间内避免再次调度任务到这些节点上。通过这种机制，MapReduce 保证了在节点宕机、数据异常等场景下的 容错性与任务的最终可完成性，体现了其在大数据处理中的鲁棒性设计。


## 大数据相关面试题每日五问（六）25.4.12

### 6.1 MapReduce的Shuffle过程是怎样的？

在 MapReduce 中，Shuffle 是连接 Map 阶段和 Reduce 阶段的核心过程，主要包括数据的输出、传输与排序。具体来说，当 Map Task 处理完数据后，会将输出结果按照 key 进行分区（Partition），写入本地磁盘的环形缓冲区，同时进行 本地排序（Sort）和可选的 Combiner 本地聚合。随后 Reduce Task 会通过 HTTP 拉取（Fetch） 所有 Map 输出的属于自己分区的数据块，这就是跨节点的数据 Shuffle。拉取完成后，Reduce 端还会对所有数据进行 归并排序（Merge Sort），以保证相同 key 的 value 是聚集在一起的，便于后续聚合处理。Shuffle 涉及大量的磁盘 IO 和网络 IO，是整个 MapReduce 性能瓶颈所在。通过优化 partition 策略、开启 Combiner、本地聚合等手段，可以有效减少 Shuffle 开销，提升作业整体效率。


### 6.2 为什么Shuffle可能会成为MR任务的性能瓶颈？如何优化？

Shuffle 之所以可能成为 MapReduce 任务的性能瓶颈，是因为它涉及 大量的磁盘读写、网络传输和数据排序操作，尤其在数据量大或 key 倾斜时，会导致任务处理时间大幅增加。具体瓶颈包括：Map 端输出写磁盘、本地排序占内存、Reduce 端拉取数据的网络开销、以及大量小文件或数据倾斜造成负载不均等。为了优化 Shuffle，可以采取以下策略：一是使用 Combiner 减少中间数据量；二是调整 Partitioner 策略，避免 key 倾斜；三是合理设置 Map/Reduce 的个数 与 内存参数，提升并行度和缓冲区容量；四是开启 压缩（如 Snappy） 减少 IO 量；五是优化 磁盘与网络资源配置，提升数据读写与传输效率。通过这些手段，可以显著缓解 Shuffle 对性能的影响，提高 MapReduce 任务整体的执行效率和稳定性。


### 6.3 MySQL的联合查询（JOIN）有哪几种类型，它们之间有什么区别？

MySQL 中常见的联合查询（JOIN）有四种类型：内连接（INNER JOIN）、左连接（LEFT JOIN）、右连接（RIGHT JOIN） 和 全连接（FULL JOIN，MySQL 需通过 UNION 实现）。INNER JOIN 只返回两张表中匹配的记录，常用于关联查询；LEFT JOIN 会返回左表的所有记录，即使右表无匹配，也会以 NULL 填充右表字段；RIGHT JOIN 与其相反，返回右表的所有记录，即使左表无匹配也会用 NULL 补齐左表字段；而 FULL JOIN 返回左右两表中所有记录，只要一方有匹配就保留，另一方没有则补 NULL。它们的主要区别在于是否保留未匹配的记录，使用时需根据业务需求选择合适的 JOIN 类型，从而确保查询结果的完整性和准确性。


### 6.4 MySQL中的GROUP BY和ORDER BY有什么区别？

在 MySQL 中，GROUP BY 和 ORDER BY 是两种不同的子句，分别用于分组聚合和排序操作。GROUP BY 是将查询结果按指定字段分组，常与聚合函数（如 COUNT、SUM、AVG 等）配合使用，对每一组数据进行统计处理，比如统计每个部门的人数；而 ORDER BY 是用于将查询结果按指定字段进行升序（ASC）或降序（DESC）排列，控制结果的展示顺序。两者的区别在于：GROUP BY 是为了归类、合并记录，ORDER BY 是为了排序展示，不改变记录数量。它们也可以同时使用，比如先分组统计，再按统计结果排序，从而实现对聚合结果的有序输出。理解这两者的区别，有助于更灵活地组织查询逻辑。


### 6.5 什么是ETL过程？在数据仓库建设中，ETL的角色和重要性是什么？

ETL 是数据仓库建设中的核心过程，指的是 Extract（抽取）、Transform（转换）、Load（加载），即从多个异构数据源中抽取原始数据，经过清洗、格式转换、校验、整合等处理后，加载到数据仓库中。ETL 是数据从“原始混乱”到“统一规范”的关键桥梁，它决定了数据的质量、结构和可用性。抽取阶段关注数据获取的效率与完整性，转换阶段实现数据标准化与业务规则处理，而加载阶段则需保障数据一致性与加载效率。在数据仓库中，ETL 是数据生命周期的起点，其稳定性和准确性直接影响数据分析、报表和决策的可信度，因此在整个数据体系中具有举足轻重的作用。


## 大数据相关面试题每日五问（七）25.4.13

### 7.1 在数仓设计中，如何确保数据的质量和一致性？应采取哪些措施？

为了确保数据仓库中的数据质量与一致性，应从多个方面着手。首先，建立严格的数据标准和业务规则，统一数据格式、单位和命名规范；其次，在 ETL 过程中对原始数据进行清洗、校验与转换，例如去重、空值处理、异常值识别、数据类型转换等；第三，采用数据血缘和数据校验机制，跟踪数据来源和处理流程，确保加工逻辑可追溯；此外，还应设置 质量监控指标和告警机制，及时发现数据延迟、错误、丢失等问题。最后，数据仓库应通过 主键约束、外键关系、事务控制和版本管理 等方式，强化数据的一致性和完整性。


### 7.2 解释一下MySQL中的索引，以及它是如何提高查询性能的。

MySQL 中的索引相当于书本的目录，用于加速数据的查找。其本质是对表中某列或多列的值建立的有序数据结构（如 B+ 树或哈希），可以极大减少查询时的扫描数据量。比如使用索引查询某个字段，只需通过索引快速定位数据所在页，而无需全表扫描。MySQL 常见的索引类型包括：主键索引（PRIMARY）、唯一索引（UNIQUE）、普通索引（INDEX）和全文索引（FULLTEXT）。索引在提升 SELECT 性能方面作用显著，但也会占用空间并影响 INSERT/UPDATE 的效率，因此需合理设计，避免过多无效索引或重复索引。


### 7.3 MySQL中如何处理NULL值？NULL值在查询和比较时有什么特殊的处理方式？

在 MySQL 中，NULL 表示“未知”或“无值”，不是 0 或空字符串。由于 NULL 表示不确定，它在查询和比较中具有特殊行为：任何值与 NULL 进行运算或比较，结果仍为 NULL（即“未知”），而不是 true 或 false。因此不能用 = 来判断 NULL，必须使用 IS NULL 或 IS NOT NULL。在排序时，NULL 默认排在最前（ASC）或最后（DESC）；在聚合函数中，COUNT(*) 会统计 NULL，而 COUNT(字段) 不会；同时在 JOIN 时，若连接字段有 NULL 值，可能导致匹配失败。因此在处理 NULL 时要格外注意业务语义和查询逻辑的严谨性。


### 7.4 简述Secondary NameNode及其作用，它和Standby NameNode 有什么区别？

Secondary NameNode 是 HDFS 架构中一个辅助角色，主要用于帮助 NameNode 合并 fsimage（元数据快照）和 edits（日志） 文件，避免 edits 日志无限增长，降低 NameNode 重启恢复时间。它不是 NameNode 的热备，而是定期拉取 NameNode 的元数据，在本地合并并回传合并结果。而 Standby NameNode 是在 HA（高可用）架构中与 Active NameNode 成对运行的热备节点，通过共享存储与日志同步，实现 NameNode 宕机后的秒级切换，保障 HDFS 的高可用。因此二者的根本区别在于：Secondary 仅做合并优化，不参与主备切换；Standby 是为高可用服务的真正备用节点。


### 7.5 ES提供了两种查询方式。请描述它们的区别，并举例说明适用场景。

Elasticsearch 提供两种主要的查询方式：Query DSL 中的全文检索（Full-text Queries） 和 精确匹配查询（Term-level Queries）。全文检索查询（如 match、multi_match）是针对文本字段，ES 会对查询词和文档进行分词处理，适用于搜索引擎类场景，如模糊搜索文章标题、产品名称等；而精确查询（如 term、range、terms）是对未分词字段进行的精确匹配，常用于结构化字段的查询，如用户 ID、状态值、时间范围等。简单来说，全文查询用于“查找相关内容”，精确查询用于“筛选确定值”，理解这两类查询的差异对于优化搜索准确性和性能非常关键。


## 大数据相关面试题每日五问（八）25.4.17

### 8.1 HDFS 如何实现数据冗余存储？数据节点宕机时，集群如何恢复数据？

HDFS 通过副本机制实现数据冗余存储，默认将每个文件划分为多个 block，每个 block 会被复制成 3 个副本（可配置），分别存储在不同的 DataNode 上。NameNode 负责记录这些副本的元数据。当某个 DataNode 宕机后，NameNode 会通过心跳机制发现节点失联，并将其标记为不可用，同时指派其他正常的 DataNode 根据现有副本重新复制缺失数据，确保副本数量不低于设定值，从而实现故障自动恢复和数据高可用。这个过程对用户是透明的，集群仍可提供读写服务。

### 8.2 Spark 中 RDD、DataFrame 和 Dataset 的核心区别是什么？实际处理数据时如何选择？

RDD 是 Spark 最底层的抽象，提供面向对象的操作方式，具备强类型、惰性计算和容错特性，但开发复杂、性能不高；DataFrame 是以 RDD 为基础的结构化数据集，类比关系型表，支持 SQL 风格的查询和 Catalyst 优化器优化，执行效率更高但类型安全较弱；Dataset 结合了 RDD 的强类型和 DataFrame 的性能优势，支持编译期类型检查及优化执行，但主要在 Scala 和 Java 中使用。在实际应用中，若需高性能查询且不依赖强类型，推荐使用 DataFrame；如需类型安全或复杂逻辑处理，可选择 Dataset；而 RDD 更适合底层控制和非结构化数据处理。

### 8.3 Hive 与 MySQL 在数据存储、查询执行和应用场景上有哪些关键差异？

Hive 构建在 Hadoop 上，面向大数据的批处理场景，数据通常存储在 HDFS 上，查询通过转换为 MapReduce、Tez 或 Spark 等分布式计算任务执行，适合海量离线分析，查询延迟较高；MySQL 是传统关系型数据库，数据存储在本地磁盘，查询响应快速，适用于高并发的 OLTP 事务处理场景。Hive 查询支持海量数据和复杂分析，适合数据仓库、报表统计；而 MySQL 更适合业务系统中小规模数据的增删改查。总结来说：Hive 面向分析型（OLAP）场景，MySQL 面向事务型（OLTP）业务。

### 8.4 数据仓库维度建模中，事务型事实表和周期快照事实表的设计区别是什么？举例说明。

事务型事实表记录的是粒度最细的事件数据，如用户每一次下单或点击行为，通常每条记录代表一个事件，适合统计某段时间内的行为总量或趋势；而周期快照事实表则在固定时间点（如每日/每月）汇总一次数据快照，记录某一维度下的累积状态，例如每天的库存快照或每日账户余额。前者设计更细致、数据量更大，适合事件追踪；后者更适合展示变化趋势或对比分析。例如：电商平台的订单表是事务型事实表，而每日商品库存快照表是周期快照事实表。

### 8.5 使用 ClickHouse 进行高频查询时，如何通过表引擎选择和分区排序键优化性能？

在 ClickHouse 中，高频查询性能依赖于合理的表引擎和数据组织方式。常用的 MergeTree 引擎支持分区（partition）和排序键（order by），可以显著提升查询效率。分区键应根据业务维度选择，如按日期或地区分区，便于按需读取数据块，减少 IO；排序键则决定数据的物理存储顺序，应选择常用查询条件字段（如 user_id、event_time），以优化数据扫描和索引利用。对于日志类、用户行为类数据，建议使用 ReplacingMergeTree 或 SummingMergeTree 做去重或聚合优化。总之，合理设计分区与排序键是 ClickHouse 高性能查询的关键手段。


## 大数据相关面试题每日五问（九）25.4.18

### 9.1 YARN 的资源调度器在多租户场景下的核心区别是什么？如何选择？

YARN 提供了三种主流资源调度器：CapacityScheduler、FairScheduler 和 FIFO，其中 CapacityScheduler 按队列设置容量和权重，适合多租户之间资源隔离和稳定保障；FairScheduler 则强调公平分配资源，空闲资源自动分配给需要的任务，适合资源动态抢占、并发任务高的场景；而 FIFO 是默认调度器，按任务提交顺序执行，适合简单单租户环境。在多租户场景中，若任务具有 SLA 要求，需保障资源分配，优先选择 CapacityScheduler；若追求资源高利用率和公平性，可选用 FairScheduler。

### 9.2 Spark Shuffle 过程中，数据倾斜通常有哪些表现？你会采取哪些优化手段？

Spark Shuffle 过程中数据倾斜主要表现为：某些 task 执行时间远高于其他 task，导致整体 stage 被拖慢，常发生在 groupByKey、reduceByKey、join 等宽依赖操作中，尤其是 key 分布不均时。优化方法包括：1）使用 map-side 聚合（如 combineByKey 替代 groupByKey）减少数据量；2）对热点 key 做“key 拆分+随机前缀+后聚合”；3）采用广播 join，避免大表与小表 shuffle；4）通过 repartition 或 coalesce 合理调整分区数；5）设置 spark.sql.adaptive.enabled=true 启用 AQE 动态优化，自动处理倾斜。

### 9.3 Hive 中分区表 Partition 和分桶表 Bucket 的设计目的是什么？实际使用时如何抉择？

Hive 中的分区（Partition）是将表按某列的值水平划分为多个目录，减少扫描范围，提升查询性能，适用于大范围过滤字段（如按天、地区查询）；分桶（Bucket）是将数据按某列 hash 后再分成若干文件，提升 join、采样查询效率，适用于分布均匀、join 频繁的列。实际使用中，若查询常根据某字段过滤，应使用分区；若需高效 join 或 map-side join，可使用分桶；两者也可结合使用，但过多分区或分桶会导致元数据膨胀和小文件问题，需权衡使用。

### 9.4 MySQL 的索引在哪些场景下会失效？请举例说明常见的索引优化误区。

MySQL 的索引会在以下场景中失效：如 where 条件中对索引列使用函数或运算（如 where year(create_time)=2023）、模糊匹配左侧加通配符（如 like '%abc'）、范围查询后再排序（如 where age > 20 order by name）、组合索引未按最左前缀原则使用。此外，错误使用覆盖索引、盲目建立过多索引、忽略更新代价等都是常见误区。例如给频繁变动的低基数字段建索引反而拖慢写入性能，需综合分析字段选择性和业务场景来优化索引设计。

### 9.5 数据仓库中处理缓慢变化维 SCD 时，类型 1 和类型 2 策略的核心差异是什么？如何实现类型 2 维表的历史数据保留？

缓慢变化维（SCD）处理维表字段随时间变化的问题，其中类型1策略直接覆盖旧值，不保留历史，适用于不关心历史变更的维度（如手机号）；而类型2策略保留历史版本，新增一条记录标记生效时间和失效时间（或添加当前标志字段），适用于分析历史状态变化（如客户等级、地区）。实现方式为：新增字段如 start_date、end_date、is_current，每次更新新插入一条记录，并将旧记录标记为历史，保证维度追溯性。


## 大数据相关面试题每日五问（十）25.4.21
    个人简历强相关
### 10.1 在 Pandas 中，除了删除缺失值，还有哪些处理方式？如何依据数据特征选择合适的处理方法？
在 Pandas 中处理缺失值除了删除（dropna()）外，还可使用 fillna() 进行填充，如用均值、中位数、众数、固定值、前值（ffill）或后值（bfill）等方式；也可以利用插值方法（如线性插值）、模型预测或其他变量相关性进行推测填充。选用方法需依据字段类型与业务背景：如数值型字段常用均值或中位数填补，时间序列数据更适合用前后值填充，而分类变量可用众数或“未知”标记填充。目标是在最大限度保留数据样本的同时，减少对分析结果的干扰。

### 10.2 SQL 窗口函数与聚合函数的核心区别是什么？请举例说明窗口函数在分组排名场景中的应用。
SQL 中聚合函数（如 SUM、AVG）会将一组记录合并为一条，不能保留明细行；而窗口函数（如 ROW_NUMBER()、RANK()、SUM() OVER(...)）则可以在保留每一行数据的前提下，进行分组计算、排序、排名等操作。比如在订单表中统计每个用户下订单金额的排名：ROW_NUMBER() OVER(PARTITION BY user_id ORDER BY amount DESC)，就能对每个用户内部的订单进行逐行排名，这是聚合函数无法实现的。

### 10.3 星型模型和雪花模型在数据仓库建模中如何抉择？分别简述它们的利弊。
星型模型以中心事实表连接多个维度表，结构简单、查询性能高、维护方便，适合对查询响应速度要求高的场景，但维度表可能存在冗余；雪花模型则对维度进一步规范化，建立多层级维度表，存储更节省、数据一致性更强，但查询复杂度高、性能略低。选择时需权衡业务需求：若强调查询效率与易用性，优选星型模型；若注重数据规范性与多层维度建模，适合使用雪花模型。

### 10.4 数仓分层架构里，ODS 层与 DWD 层的主要差异是什么？各自承载什么功能？
ODS 层（Operational Data Store）是原始数据的存储层，承载从业务系统抽取来的原始明细数据，做轻度清洗转码，保持数据的原始性和可追溯性；DWD 层（Data Warehouse Detail）是在 ODS 基础上完成业务规则处理与字段解析，形成标准化、宽表结构的明细数据，是数据仓库中最关键的“公共明细层”。ODS 更偏向于数据“落地”，DWD 承担“整合+标准化输出”的功能，是后续指标计算和分析建模的基础。

### 10.5 基于 DAG 的任务调度（如模拟 Airflow）在 ETL 流程设计中有何优势？怎样处理任务间的依赖关系？
基于 DAG（有向无环图）的任务调度可以清晰定义 ETL 流程中各个任务的执行顺序与依赖关系，支持自动化调度、失败重试、依赖检查、任务状态追踪等功能，极大提升 ETL 的可维护性与稳定性。在实现中，任务之间的依赖关系通过配置上下游（如 set_upstream()、set_downstream()）或编排依赖参数指定，调度器则会自动按照 DAG 拓扑结构管理任务执行，确保整体流程有序且高效执行。
